/*************************************************************
 *  Empathy-Canvas Interviewer â€“ hard-coded research   v1.4
 *  â€¢ Inbound Twilio call  â†’ Whisper â†’ GPT-4o Realtime
 *  â€¢ Saves call-transcript.json      (report generation optional)
 *  â€¢ Handles the timing race + sends streamSid so audio plays back
 *************************************************************/
import fs from 'fs';
import Fastify from 'fastify';
import WebSocket from 'ws';
import dotenv from 'dotenv';
import fastifyWs from '@fastify/websocket';
import fastifyFormBody from '@fastify/formbody';
import { spawn } from 'child_process';

dotenv.config();
const { OPENAI_API_KEY, MODEL = 'gpt-4o-2024-05-13' } = process.env;
if (!OPENAI_API_KEY) throw new Error('Missing OPENAI_API_KEY');

const fastify = Fastify();
fastify.register(fastifyFormBody);
fastify.register(fastifyWs);

// â¬‡ simple POST /context   { "research": "...", "style": "direct" }
let CURRENT_CONTEXT = { research: '', style: 'direct' };

fastify.post('/context', async (req, reply) => {
  const { research = '', style = 'direct' } = req.body || {};
  CURRENT_CONTEXT = { research, style };
  
  console.log('ğŸ“ context updated', CURRENT_CONTEXT);
  reply.send({ ok: true });
});



/* escape &,<,> for TwiML */
const xmlEscape = s => s.replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;');

/* â”€â”€â”€â”€â”€  SYSTEM PROMPT  (â† put your full prompt here) â”€â”€â”€â”€â”€ */
const SYSTEM_MESSAGE = ({ research, style }) => `
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SYSTEM PROMPT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ ROLE                                                                             â”‚
â”‚   You are **EmpathyAgent**, a warm, adaptive conversationalist who speaks to ONE  â”‚
â”‚   human over the phone (Twilio audio).                                            â”‚
â”‚                                                                                  â”‚
â”‚ PURPOSE                                                                           â”‚
â”‚   Hold a natural, rapport-building conversation that quietly gathers everything   â”‚
â”‚   needed to populate an **Empathy Canvas**.  The caller should feel like they     â”‚
â”‚   just had a good chat with an interested personâ€”not an interrogation.            â”‚
â”‚                                                                                  â”‚
â”‚ RUNTIME INPUTS (never reveal)                                                     â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚   â€¢ ${{research}}                                                             â”‚
â”‚       â€“ A multi-paragraph briefing that gives you:                                â”‚
â”‚         Â· the **domain / field** (e.g., health, sports, entrepreneurship)        â”‚
â”‚         Â· typical **personas** and roles you might meet                           â”‚
â”‚         Â· the overarching **problem space or challenge** being explored           â”‚
â”‚         Â· key vocabulary, events, or trends                                       â”‚
â”‚       â€“ Think of it as the â€œworldâ€ in which this interview takes place.           â”‚
â”‚                                                                                  â”‚
â”‚       HOW TO USE IT                                                               â”‚
â”‚         1.  Skim it silently before speaking.  Absorb domain language,            â”‚
â”‚             typical situations, and suspected root challenges.                    â”‚
â”‚         2.  Let it DRIVE which topics you probe and how you phrase follow-upsâ€”    â”‚
â”‚             choose metaphors, anecdotes, and terminology that feel native         â”‚
â”‚             to that field.                                                        â”‚
â”‚         3.  Do **not** quote or reference the text itself.  Instead, weave its    â”‚
â”‚             knowledge into organic, context-appropriate questions and empathy.    â”‚
â”‚                                                                                  â”‚
â”‚   â€¢ {{MAX_MINUTES}} = 20 minutes                     â”‚
â”‚                                                                                  â”‚
â”‚ INTERNAL CANVAS OBJECT (never spoken)                                             â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚   { "name":"", "bio":"", "see":"", "hear":"", "do":"",                            â”‚
â”‚     "think_feel":"", "pains":"", "gains":"",                                      â”‚
â”‚     "_conf":      { "<each slot>":0 },                                            â”‚
â”‚     "_why_depth": { "<each slot>":0 } }                                           â”‚
â”‚                                                                                  â”‚
â”‚   â€¢ '_conf' (0â€“1) â€“ confidence/completeness.  Start 0.0; +0.3 for a concrete      â”‚
â”‚     new detail; +0.2 when caller elaborates or confirms; cap 1.0.                 â”‚
â”‚   â€¢ '_why_depth'  â€“ how many motive/meaning layers you have dug (0-4).            â”‚
â”‚   â€¢ Update both after every caller turn inside '<!-- INTERNAL â€¦ -->' comments.    â”‚
â”‚                                                                                  â”‚
â”‚ CONVERSATION FLOW (conceptual guide)                                              â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ 1âƒ£  Welcome & consent                                                             â”‚
â”‚ 2âƒ£  Rapport & background (â‰¤ ~2 min) â€“ learn who they are **within the domain**    â”‚
â”‚ 3âƒ£  First canvas sweep  (finish by ~10 min) â€“ cover every slot using domain-aware â”‚
â”‚     open prompts.                                                                 â”‚
â”‚ 4âƒ£  Depth loops â€“ indirect 5-Whys for unclear slots.                              â”‚
â”‚ 5âƒ£  Graceful wrap-up â€“ when '_conf' targets met, info-gain stalls, fatigue, or    â”‚
â”‚     time cap.                                                                     â”‚
â”‚ 6âƒ£  Send:  ###EMPATHY_CANVAS###  {<full JSON canvas>}                             â”‚
â”‚                                                                                  â”‚
â”‚ STYLE PRINCIPLES                                                                  â”‚
â”‚   â€¢ Sound like two people sharing stories; let each answer steer the next prompt. â”‚
â”‚   â€¢ Mirror callerâ€™s vocabulary, tone, energyâ€”using terms natural to               â”‚
â”‚     {{DEEP_RESEARCH}}â€™s field.                                                    â”‚
â”‚   â€¢ One open question per turn, brief empathetic acknowledgements.                â”‚
â”‚   â€¢ Softly rephrase or pivot if caller stalls.                                    â”‚
â”‚   â€¢ Never mention â€œcanvasâ€, â€œslotsâ€, â€œfive whysâ€, research docs, or internals.    â”‚
â”‚                                                                                  â”‚
â”‚ SAFETY                                                                            â”‚
â”‚   â€¢ Defer on medical / legal / financial advice (â€œIâ€™m not a professionalâ€).       â”‚
â”‚   â€¢ Respect any request to skip or end the call immediately.                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
`
;
/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

const VOICE = 'alloy';
const PORT  = process.env.PORT || 5050;

/* ---------- Twilio webhook ---------- */
fastify.all('/incoming-call', (req, reply) => {
  console.log('âœ… Twilio /incoming-call was triggered: ' + new Date().toISOString());
  const wsURL = `wss://${req.headers.host}/media-stream`;
  reply.type('text/xml').send(`<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Say>Connecting you to your interviewer.</Say>
  <Connect><Stream url="${xmlEscape(wsURL)}" /></Connect>
</Response>`);
});

// Serve the generated report JSON
fastify.get('/call-report.json', (request, reply) => {
  try {
    const data = fs.readFileSync('call-report.json', 'utf8');
    reply.header('Content-Type', 'application/json').send(data);
  } catch (err) {
    reply.status(404).send({ error: 'Report not found' });
  }
});

// (Optional) Serve the transcript JSON
fastify.get('/call-transcript.json', (request, reply) => {
  try {
    const data = fs.readFileSync('call-transcript.json', 'utf8');
    reply.header('Content-Type', 'application/json').send(data);
  } catch (err) {
    reply.status(404).send({ error: 'Transcript not found' });
  }
});

/* ---------- Media stream ---------- */
fastify.register(async () => {
  fastify.get('/media-stream', { websocket:true }, (conn) => {
    console.log('ğŸ”—  caller connected');

    const transcript = [];
    let streamSid    = null;
    let openAiReady  = false;
    const pending    = [];

    /* -------- finalize: runs once when call ends -------- */
    const finalize = () => {
      if (finalize.done) return;        // ensure idempotent
      finalize.done = true;

      // 1ï¸âƒ£  write raw transcript
      fs.writeFileSync(
        'call-transcript.json',
        JSON.stringify(transcript, null, 2),
        'utf8'
      );
      console.log('ğŸ“„  call-transcript.json written');

      // 2ï¸âƒ£  spawn report.js in a child process
      const child = spawn('node', ['report.js'], {
        cwd: process.cwd(),   // same directory
        stdio: 'inherit',     // pipe its logs to Azure logâ€‘stream
        env: process.env      // pass OPENAI_API_KEY, etc.
      });

      child.on('exit', code =>
        console.log(`ğŸ“‘ report.js finished (exit ${code})`)
      );
    };

    /* -------- connect to OpenAI Realtime -------- */
    const oa = new WebSocket(
      'wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01',
      { headers:{
          Authorization:`Bearer ${OPENAI_API_KEY}`,
          'OpenAI-Beta':'realtime=v1'
        }}
    );

    oa.once('open', () => {
      openAiReady = true;
      oa.send(JSON.stringify({
        type:'session.update',
        session:{
          turn_detection:{type:'server_vad'},
          input_audio_format:'g711_ulaw',
          input_audio_transcription:{model:'whisper-1'},
          output_audio_format:'g711_ulaw',
          voice:VOICE,
          instructions:SYSTEM_MESSAGE(CURRENT_CONTEXT),
          modalities:['text','audio'],
          temperature:0.8
        }
      }));
      pending.forEach(a =>
        oa.send(JSON.stringify({type:'input_audio_buffer.append',audio:a})));
      pending.length = 0;
    });

    oa.on('message', buf => {
      const e = JSON.parse(buf.toString());
      if (e.type==='conversation.item.input_audio_transcription.completed' && e.transcript)
        transcript.push({speaker:'user',text:e.transcript});
      if (e.type==='response.audio_transcript.done' && e.transcript)
        transcript.push({speaker:'assistant',text:e.transcript});
      if (e.type==='response.audio.delta' && e.delta && streamSid)
        conn.send(JSON.stringify({
          event:'media',
          streamSid,
          media:{payload:e.delta}
        }));
    });

    /* -------- Twilio â†’ OpenAI -------- */
    conn.on('message', msg => {
      const d = JSON.parse(msg);
      if (d.event==='media') {
        if (openAiReady)
          oa.send(JSON.stringify({type:'input_audio_buffer.append',audio:d.media.payload}));
        else
          pending.push(d.media.payload);
      } else if (d.event==='start') {
        streamSid = d.start.streamSid;           // capture sid
      } else if (d.event==='stop') {
        conn.close();                            // trigger close
      }
    });

    conn.on('close', () => {
      finalize();
      if (oa.readyState === WebSocket.OPEN) oa.close();
    });

    oa.on('error', console.error);
  });
});

/* ---------- start server ---------- */
+ fastify.listen({ port: PORT, host: '0.0.0.0' }, err => {
  if(err) throw err;
  console.log(`ğŸš€  Listening on port ${PORT}`);
});
